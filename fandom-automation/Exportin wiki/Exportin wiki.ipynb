{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Собираем ссылки на все файлы\n",
    "https://brainout.fandom.com/ru/wiki/%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:%D0%92%D1%81%D0%B5_%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D1%8B"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "\r\n",
    "url = 'https://brainout.fandom.com/ru/wiki/Служебная:Все_страницы?from=&to=&namespace=6'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def file_in_string(string):\r\n",
    "    return str(string).startswith('Файл:') or str(string).startswith('File:')\r\n",
    "\r\n",
    "def next_in_string(string):\r\n",
    "    return str(string).startswith('Следующая страница') or str(string).startswith('Next page')\r\n",
    "\r\n",
    "start_url = 'https://brainout.fandom.com/ru/wiki/Служебная:Все_страницы?from=&to=&namespace=6'\r\n",
    "response = requests.get(start_url)\r\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\r\n",
    "\r\n",
    "next_page = soup.find(title=\"Служебная:Все страницы\", string=next_in_string)\r\n",
    "url_arr=[]\r\n",
    "\r\n",
    "while next_page:\r\n",
    "    print('Startin url append')\r\n",
    "    for file in soup.find_all('a', string=file_in_string):\r\n",
    "        url_arr.append('https://brainout.fandom.com' + file.get('href'))\r\n",
    "    \r\n",
    "    next_page = soup.find(title=\"Служебная:Все страницы\", string=next_in_string)\r\n",
    "    print(next_page)\r\n",
    "    if next_page:\r\n",
    "        next_url = next_page.get('href')\r\n",
    "    else:\r\n",
    "        print('goin to break')\r\n",
    "        break\r\n",
    "    print('Goin for next page', next_url)\r\n",
    "    response = requests.get('https://brainout.fandom.com' + next_url)\r\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\r\n",
    "    #print(soup)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сохраняем результаты"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "import json\r\n",
    "with open('url_arr.json', 'w') as f:\r\n",
    "    json.dump(url_arr, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Открываем результаты"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\r\n",
    "with open('url_arr.json', 'r', encoding=\"utf-8\") as f:\r\n",
    "    url_arr = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "url_arr[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://brainout.fandom.com/ru/wiki/%D0%A4%D0%B0%D0%B9%D0%BB:%22%D0%A1%D0%B2%D0%BE%D0%B1%D0%BE%D0%B4%D0%BD%D0%B0%D1%8F_%D0%B8%D0%B3%D1%80%D0%B0%22_%D0%B2_%D0%B2%D0%BE%D0%BF%D1%80%D0%BE%D1%81%D0%B0%D1%85_%D0%B8_%D0%BE%D1%82%D0%B2%D0%B5%D1%82%D0%B0%D1%85.png'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Логинимся на страницу фандома\n",
    "https://www.fandom.com/signin?uselang=ru&redirect=https%3A%2F%2Fbrainout.fandom.com%2Fru%2Ff"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "start_url = 'https://www.fandom.com/signin?uselang=ru&redirect=https%3A%2F%2Fbrainout.fandom.com%2Fru%2Ff'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "%timeit\r\n",
    "from selenium import webdriver\r\n",
    "from selenium.webdriver.common.by import By\r\n",
    "from selenium.webdriver.support.ui import WebDriverWait\r\n",
    "from selenium.webdriver.support import expected_conditions as EC\r\n",
    "\r\n",
    "def login_through(driver, start_url):\r\n",
    "    driver.get(start_url)\r\n",
    "    element = driver.find_element_by_id(\"loginUsername\")\r\n",
    "    element.send_keys(\"foxinol\")\r\n",
    "    element = driver.find_element_by_id(\"loginPassword\")\r\n",
    "    element.send_keys(\"aboba\")\r\n",
    "    driver.find_element_by_id(\"loginSubmit\").click()\r\n",
    "    \r\n",
    "\r\n",
    "options = webdriver.ChromeOptions()\r\n",
    "options.page_load_strategy = 'eager'\r\n",
    "options.add_argument('--ignore-ssl-errors')\r\n",
    "options.add_argument('--ignore-certificate-errors-spki-list')\r\n",
    "options.add_argument('--ignore-ssl-errors')\r\n",
    "\r\n",
    "driver = webdriver.Chrome(options=options)\r\n",
    "login_through(driver, start_url)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### В течении логин сессии начинаем собирать ссылки на static страницы"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\r\n",
    "def full_file(string):\r\n",
    "    return str(string).startswith('Original file') or str(string).startswith('Оригинальный файл')\r\n",
    "\r\n",
    "static_links = []\r\n",
    "\r\n",
    "for count, url in enumerate(url_arr):\r\n",
    "    driver.get(url)\r\n",
    "    html = driver.page_source\r\n",
    "    soup = BeautifulSoup(html, 'lxml')\r\n",
    "    fin_file = soup.find(class_='internal')\r\n",
    "    static_links.append(fin_file.get('href'))\r\n",
    "    print(count, 'success')\r\n",
    "\r\n",
    "with open('static_links.json', 'w') as f:\r\n",
    "    json.dump(static_links, f) \r\n",
    "\r\n",
    "driver.close()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Скачиваем контент и работаем с названиями файлов"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "import json\r\n",
    "with open('url_arr_changed.json', 'r', encoding=\"utf-8\") as f:\r\n",
    "    url_arr_changed = json.load(f)\r\n",
    "with open('static_links_changed.json', 'r', encoding=\"utf-8\") as f:\r\n",
    "    static_links_changed = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def ultimate_string_check(file_name):\r\n",
    "    file_name = file_name.replace('-', '').replace('.', '').replace('(', '').replace(')', '').replace('_', '')[:-3]\r\n",
    "    if file_name.isalpha():\r\n",
    "        return \"alpha\"\r\n",
    "    elif file_name.isnumeric():\r\n",
    "        return \"number\"\r\n",
    "    elif file_name.isalnum():\r\n",
    "        return \"alnum\"\r\n",
    "    else:\r\n",
    "        return \"trash\"\r\n",
    "\r\n",
    "from urllib.parse import unquote\r\n",
    "not_worked_links = []\r\n",
    "for i in range(len(static_links)):\r\n",
    "    file_name = unquote(url_arr_changed[i].split('/')[-1][22:])\r\n",
    "    try:\r\n",
    "        urllib.request.urlretrieve(static_links[i], \"images/\" + ultimate_string_check(file_name) + \"/\" + file_name)\r\n",
    "    except OSError:\r\n",
    "        not_worked_links.append(static_links[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сохраняем необработанные ссылки"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "with open('not_worked_links.json', 'w') as f:\r\n",
    "    json.dump(not_worked_links, f) "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}